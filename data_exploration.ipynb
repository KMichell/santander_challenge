{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pydot as pt\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', low_memory = False)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "columns_train = train_df.iloc[0].values\n",
    "\n",
    "train_df.columns = columns_train\n",
    "\n",
    "train_df = train_df.drop(0, axis = 0)\n",
    "\n",
    "train_df = train_df.drop('ID_code', axis = 1)\n",
    "test_df = test_df.drop('ID_code', axis = 1)\n",
    "\n",
    "train_df = train_df.apply(pd.to_numeric)\n",
    "test_df = test_df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']\n",
    "param = {\n",
    "    'bagging_freq': 5,          'bagging_fraction': 0.38,   'boost_from_average':'false',   'boost': 'gbdt',\n",
    "    'feature_fraction': 0.045,   'learning_rate': 0.0105,     'max_depth': -1,                'metric':'auc',\n",
    "    'min_data_in_leaf': 80,     'min_sum_hessian_in_leaf': 10.0,'num_leaves': 13,           'num_threads': 8,\n",
    "    'tree_learner': 'serial',   'objective': 'binary',      'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits = 3, shuffle = False, random_state = 44000)  #split = 12\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold :1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's auc: 0.907343\tvalid_1's auc: 0.883443\n",
      "[2000]\ttraining's auc: 0.919281\tvalid_1's auc: 0.89092\n",
      "[3000]\ttraining's auc: 0.927248\tvalid_1's auc: 0.894543\n",
      "[4000]\ttraining's auc: 0.933367\tvalid_1's auc: 0.896366\n",
      "[5000]\ttraining's auc: 0.938884\tvalid_1's auc: 0.897476\n",
      "[6000]\ttraining's auc: 0.943735\tvalid_1's auc: 0.898016\n",
      "[7000]\ttraining's auc: 0.948279\tvalid_1's auc: 0.898232\n",
      "[8000]\ttraining's auc: 0.952616\tvalid_1's auc: 0.89832\n",
      "[9000]\ttraining's auc: 0.956711\tvalid_1's auc: 0.898291\n",
      "Early stopping, best iteration is:\n",
      "[8235]\ttraining's auc: 0.95358\tvalid_1's auc: 0.898349\n",
      "Fold :2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's auc: 0.906269\tvalid_1's auc: 0.883906\n",
      "[2000]\ttraining's auc: 0.918638\tvalid_1's auc: 0.892155\n",
      "[3000]\ttraining's auc: 0.926792\tvalid_1's auc: 0.895534\n",
      "[4000]\ttraining's auc: 0.933218\tvalid_1's auc: 0.897256\n",
      "[5000]\ttraining's auc: 0.938722\tvalid_1's auc: 0.898174\n",
      "[6000]\ttraining's auc: 0.943677\tvalid_1's auc: 0.898609\n",
      "[7000]\ttraining's auc: 0.94821\tvalid_1's auc: 0.898735\n",
      "Early stopping, best iteration is:\n",
      "[6625]\ttraining's auc: 0.946577\tvalid_1's auc: 0.898797\n",
      "Fold :3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's auc: 0.906094\tvalid_1's auc: 0.886142\n",
      "[2000]\ttraining's auc: 0.918023\tvalid_1's auc: 0.893342\n",
      "[3000]\ttraining's auc: 0.926179\tvalid_1's auc: 0.897131\n",
      "[4000]\ttraining's auc: 0.932512\tvalid_1's auc: 0.89906\n",
      "[5000]\ttraining's auc: 0.937983\tvalid_1's auc: 0.899903\n",
      "[6000]\ttraining's auc: 0.943013\tvalid_1's auc: 0.900243\n",
      "[7000]\ttraining's auc: 0.947793\tvalid_1's auc: 0.900341\n",
      "[8000]\ttraining's auc: 0.952064\tvalid_1's auc: 0.900526\n",
      "[9000]\ttraining's auc: 0.956073\tvalid_1's auc: 0.900595\n",
      "Early stopping, best iteration is:\n",
      "[8499]\ttraining's auc: 0.954125\tvalid_1's auc: 0.900624\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-215b022d01bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CV score: {:<8.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CV score: {:<8.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold :{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label = target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label = target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval = 1000, early_stopping_rounds = 1000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration = clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[features], num_iteration = clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.89921 CV score: 0.89921 \n"
     ]
    }
   ],
   "source": [
    "sys.stdout.write(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "#sub[\"target\"] = predictions\n",
    "#sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
       "       'var_5', 'var_6', 'var_7', 'var_8', 'var_9', 'var_10', 'var_11',\n",
       "       'var_12', 'var_13', 'var_14', 'var_15', 'var_16', 'var_17',\n",
       "       'var_18', 'var_19', 'var_20', 'var_21', 'var_22', 'var_23',\n",
       "       'var_24', 'var_25', 'var_26', 'var_27', 'var_28', 'var_29',\n",
       "       'var_30', 'var_31', 'var_32', 'var_33', 'var_34', 'var_35',\n",
       "       'var_36', 'var_37', 'var_38', 'var_39', 'var_40', 'var_41',\n",
       "       'var_42', 'var_43', 'var_44', 'var_45', 'var_46', 'var_47',\n",
       "       'var_48', 'var_49', 'var_50', 'var_51', 'var_52', 'var_53',\n",
       "       'var_54', 'var_55', 'var_56', 'var_57', 'var_58', 'var_59',\n",
       "       'var_60', 'var_61', 'var_62', 'var_63', 'var_64', 'var_65',\n",
       "       'var_66', 'var_67', 'var_68', 'var_69', 'var_70', 'var_71',\n",
       "       'var_72', 'var_73', 'var_74', 'var_75', 'var_76', 'var_77',\n",
       "       'var_78', 'var_79', 'var_80', 'var_81', 'var_82', 'var_83',\n",
       "       'var_84', 'var_85', 'var_86', 'var_87', 'var_88', 'var_89',\n",
       "       'var_90', 'var_91', 'var_92', 'var_93', 'var_94', 'var_95',\n",
       "       'var_96', 'var_97', 'var_98', 'var_99', 'var_100', 'var_101',\n",
       "       'var_102', 'var_103', 'var_104', 'var_105', 'var_106', 'var_107',\n",
       "       'var_108', 'var_109', 'var_110', 'var_111', 'var_112', 'var_113',\n",
       "       'var_114', 'var_115', 'var_116', 'var_117', 'var_118', 'var_119',\n",
       "       'var_120', 'var_121', 'var_122', 'var_123', 'var_124', 'var_125',\n",
       "       'var_126', 'var_127', 'var_128', 'var_129', 'var_130', 'var_131',\n",
       "       'var_132', 'var_133', 'var_134', 'var_135', 'var_136', 'var_137',\n",
       "       'var_138', 'var_139', 'var_140', 'var_141', 'var_142', 'var_143',\n",
       "       'var_144', 'var_145', 'var_146', 'var_147', 'var_148', 'var_149',\n",
       "       'var_150', 'var_151', 'var_152', 'var_153', 'var_154', 'var_155',\n",
       "       'var_156', 'var_157', 'var_158', 'var_159', 'var_160', 'var_161',\n",
       "       'var_162', 'var_163', 'var_164', 'var_165', 'var_166', 'var_167',\n",
       "       'var_168', 'var_169', 'var_170', 'var_171', 'var_172', 'var_173',\n",
       "       'var_174', 'var_175', 'var_176', 'var_177', 'var_178', 'var_179',\n",
       "       'var_180', 'var_181', 'var_182', 'var_183', 'var_184', 'var_185',\n",
       "       'var_186', 'var_187', 'var_188', 'var_189', 'var_190', 'var_191',\n",
       "       'var_192', 'var_193', 'var_194', 'var_195', 'var_196', 'var_197',\n",
       "       'var_198', 'var_199'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[columns_train[2:]], \n",
    "                                                    train_df[columns_train[1]], \n",
    "                                                    test_size = 0.3, random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 200) (60000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work with X_train, X_test, y_train, y_test\n",
    "# Create an object of Logistic Regression with parameters C and class_weight\n",
    "logist = LogisticRegression(C = 0.001, class_weight = 'balanced')\n",
    "\n",
    "# Fit the training data on this object\n",
    "logist.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Target for validation dataset \n",
    "logist_pred = logist.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(Y_test, logist_pred):\n",
    "    logist_pred_var = [0 if i < 0.5 else 1 for i in logist_pred]\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(Y_test, logist_pred_var)) \n",
    "      \n",
    "    #print(classification_report(Y_test, logist_pred)) \n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, logist_pred, pos_label = 1)\n",
    "    print('AUC:')\n",
    "    print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[42214 11737]\n",
      " [ 1404  4645]]\n",
      "AUC:\n",
      "0.8541974369026266\n"
     ]
    }
   ],
   "source": [
    "performance(y_test, logist_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=0.7, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=80, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=2019,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Decision Tree Classifier object with few parameters\n",
    "tree_clf = DecisionTreeClassifier(class_weight = 'balanced', random_state = 2019, \n",
    "                                  max_features = 0.7, min_samples_leaf = 80)\n",
    "\n",
    "# Fit the object on training data\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[35314 18637]\n",
      " [ 2629  3420]]\n",
      "AUC:\n",
      "0.6514727493199708\n"
     ]
    }
   ],
   "source": [
    "# Predict for validation set and check the performance\n",
    "tree_preds = tree_clf.predict_proba(X_test)[:, 1]\n",
    "performance(y_test, tree_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random Forest Object using the mentioned parameters\n",
    "random_forest = RandomForestClassifier(n_estimators = 25, random_state = 2019, verbose = 1, #n_estimators = 100\n",
    "                                      class_weight = 'balanced', max_features = 0.5, \n",
    "                                       min_samples_leaf = 25) # min_samples_leaf = 100\n",
    "\n",
    "# Fit the object on training set \n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the validation set target and check the performance\n",
    "forest_preds = random_forest.predict_proba(X_test)[:, 1]\n",
    "performance(y_test, forest_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Dropout, RepeatVector, Lambda, Permute, Activation, Masking, Reshape\n",
    "from keras.layers import recurrent, Input, TimeDistributed, add, concatenate, Multiply, Bidirectional\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.metrics import categorical_accuracy\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "#from keras.utils.visualize_util import plot\n",
    "from keras.layers.core import Layer\n",
    "\n",
    "from keras.activations import softmax, tanh, sigmoid, hard_sigmoid, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(in_shape):\n",
    "    adam = Adam(lr = 0.0003)  # Best learning found in previous exp\n",
    "    input_layer = Input(shape = (in_shape,), name = 'input_layer')\n",
    "    dense = Dense(100, activation = 'relu')(input_layer)\n",
    "    #dense = Dropout(0.35)(dense)\n",
    "    dense = Dense(50, activation = 'relu')(dense)\n",
    "    dense = Dropout(0.30)(dense)\n",
    "    output = Dense(2, activation = 'softmax')(dense)\n",
    "    model = Model(inputs = input_layer, outputs = output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    #model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    #tf_thetas = tf.get_variable(\"tf_thetas\",\n",
    "    #                        initializer=thetas)\n",
    "\n",
    "    #sample_output = Lambda(lambda x: \n",
    "    #               gumbel_softmax(x, temperature,  hard = hard_val), \n",
    "    #               output_shape = (2,))(output)\n",
    "    #cond_prob = Lambda(lambda x: tf.einsum('ai,ij->aj', x[0], tf_thetas*1.),\n",
    "    #          output_shape = (2, ))([sample_output])\n",
    "\n",
    "    #model_ask = Model(inputs = input_layer, outputs = cond_prob)\n",
    "    #model_ask.compile(loss = 'categorical_crossentropy', \n",
    "    #              optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model#, model_ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.choice(len(X_train), len(X_train), replace = False)\n",
    "\n",
    "X_train_nn = X_train.iloc[random_idx]\n",
    "y_train_nn = y_train.iloc[random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = create_models(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary_train = to_categorical(y_train)\n",
    "y_binary_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make severl models, computes and average them. Consider Kfold, SVM, NN, Logisteic Regression, Light GBM and several configurations of them\n",
    "h = model.fit(X_train, y_binary_train, \n",
    "              epochs = 50, validation_data = (X_test, y_binary_test),\n",
    "              batch_size = 25,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nn_predic = []\n",
    "for i in range(len(y_predicted_nn)):\n",
    "    if y_predicted_nn[i,0] > y_predicted_nn[i,1]:\n",
    "        temp_nn_predic.append(0)\n",
    "    else:\n",
    "        temp_nn_predic.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no gain with more layers!\n",
    "fpr_nn, tpr_nn, threshold_nn = roc_curve(y_test, temp_nn_predic)\n",
    "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_nn, tpr_nn, 'b', label = 'AUC = %0.2f' % roc_auc_nn)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: run several configurations for each model, then combine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
