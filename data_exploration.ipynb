{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pydot as pt\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', low_memory = False)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "columns_train = train_df.iloc[0].values\n",
    "\n",
    "train_df.columns = columns_train\n",
    "\n",
    "train_df = train_df.drop(0, axis = 0)\n",
    "\n",
    "train_df = train_df.drop('ID_code', axis = 1)\n",
    "test_df = test_df.drop('ID_code', axis = 1)\n",
    "\n",
    "train_df = train_df.apply(pd.to_numeric)\n",
    "test_df = test_df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8      ...              var_190  \\\n",
       "count  200000.000000  200000.000000      ...        200000.000000   \n",
       "mean       16.545850       0.284162      ...             3.234440   \n",
       "std         3.418076       3.332634      ...             4.559922   \n",
       "min         5.349700     -10.505500      ...           -14.093300   \n",
       "25%        13.943800      -2.317800      ...            -0.058825   \n",
       "50%        16.456800       0.393700      ...             3.203600   \n",
       "75%        19.102900       2.937900      ...             6.406200   \n",
       "max        27.691800      10.151300      ...            18.440900   \n",
       "\n",
       "             var_191        var_192        var_193        var_194  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        7.438408       1.927839       3.331774      17.993784   \n",
       "std         3.023272       1.478423       3.992030       3.135162   \n",
       "min        -2.691700      -3.814500     -11.783400       8.694400   \n",
       "25%         5.157400       0.889775       0.584600      15.629800   \n",
       "50%         7.347750       1.901300       3.396350      17.957950   \n",
       "75%         9.512525       2.949500       6.205800      20.396525   \n",
       "max        16.716500       8.402400      18.281800      27.928800   \n",
       "\n",
       "             var_195        var_196        var_197        var_198  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       -0.142088       2.303335       8.908158      15.870720   \n",
       "std         1.429372       5.454369       0.921625       3.010945   \n",
       "min        -5.261000     -14.209600       5.960600       6.299300   \n",
       "25%        -1.170700      -1.946925       8.252800      13.829700   \n",
       "50%        -0.172700       2.408900       8.888200      15.934050   \n",
       "75%         0.829600       6.556725       9.593300      18.064725   \n",
       "max         4.272900      18.321500      12.000400      26.079100   \n",
       "\n",
       "             var_199  \n",
       "count  200000.000000  \n",
       "mean       -3.326537  \n",
       "std        10.438015  \n",
       "min       -38.852800  \n",
       "25%       -11.208475  \n",
       "50%        -2.819550  \n",
       "75%         4.836800  \n",
       "max        28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']\n",
    "param = {\n",
    "    'bagging_freq': 5,          'bagging_fraction': 0.38,   'boost_from_average':'false',   'boost': 'gbdt',\n",
    "    'feature_fraction': 0.045,   'learning_rate': 0.0105,     'max_depth': -1,                'metric':'auc',\n",
    "    'min_data_in_leaf': 80,     'min_sum_hessian_in_leaf': 10.0,'num_leaves': 13,           'num_threads': 8,\n",
    "    'tree_learner': 'serial',   'objective': 'binary',      'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits = 3, shuffle = False, random_state = 44000)  #split = 12\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold :1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's auc: 0.907343\tvalid_1's auc: 0.883443\n",
      "[2000]\ttraining's auc: 0.919281\tvalid_1's auc: 0.89092\n",
      "[3000]\ttraining's auc: 0.927248\tvalid_1's auc: 0.894543\n",
      "[4000]\ttraining's auc: 0.933367\tvalid_1's auc: 0.896366\n",
      "[5000]\ttraining's auc: 0.938884\tvalid_1's auc: 0.897476\n",
      "[6000]\ttraining's auc: 0.943735\tvalid_1's auc: 0.898016\n",
      "[7000]\ttraining's auc: 0.948279\tvalid_1's auc: 0.898232\n",
      "[8000]\ttraining's auc: 0.952616\tvalid_1's auc: 0.89832\n",
      "[9000]\ttraining's auc: 0.956711\tvalid_1's auc: 0.898291\n",
      "Early stopping, best iteration is:\n",
      "[8235]\ttraining's auc: 0.95358\tvalid_1's auc: 0.898349\n",
      "Fold :2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's auc: 0.906269\tvalid_1's auc: 0.883906\n",
      "[2000]\ttraining's auc: 0.918638\tvalid_1's auc: 0.892155\n",
      "[3000]\ttraining's auc: 0.926792\tvalid_1's auc: 0.895534\n",
      "[4000]\ttraining's auc: 0.933218\tvalid_1's auc: 0.897256\n",
      "[5000]\ttraining's auc: 0.938722\tvalid_1's auc: 0.898174\n",
      "[6000]\ttraining's auc: 0.943677\tvalid_1's auc: 0.898609\n",
      "[7000]\ttraining's auc: 0.94821\tvalid_1's auc: 0.898735\n",
      "Early stopping, best iteration is:\n",
      "[6625]\ttraining's auc: 0.946577\tvalid_1's auc: 0.898797\n",
      "Fold :3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's auc: 0.906094\tvalid_1's auc: 0.886142\n",
      "[2000]\ttraining's auc: 0.918023\tvalid_1's auc: 0.893342\n",
      "[3000]\ttraining's auc: 0.926179\tvalid_1's auc: 0.897131\n",
      "[4000]\ttraining's auc: 0.932512\tvalid_1's auc: 0.89906\n",
      "[5000]\ttraining's auc: 0.937983\tvalid_1's auc: 0.899903\n",
      "[6000]\ttraining's auc: 0.943013\tvalid_1's auc: 0.900243\n",
      "[7000]\ttraining's auc: 0.947793\tvalid_1's auc: 0.900341\n",
      "[8000]\ttraining's auc: 0.952064\tvalid_1's auc: 0.900526\n",
      "[9000]\ttraining's auc: 0.956073\tvalid_1's auc: 0.900595\n",
      "Early stopping, best iteration is:\n",
      "[8499]\ttraining's auc: 0.954125\tvalid_1's auc: 0.900624\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-215b022d01bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CV score: {:<8.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CV score: {:<8.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold :{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label = target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label = target.iloc[val_idx])\n",
    "    clf = lgb.train(param, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval = 1000, early_stopping_rounds = 1000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration = clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[features], num_iteration = clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.89921 CV score: 0.89921 \n"
     ]
    }
   ],
   "source": [
    "sys.stdout.write(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "#sub[\"target\"] = predictions\n",
    "#sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[columns_train[2:]], \n",
    "                                                    train_df[columns_train[1]], \n",
    "                                                    test_size = 0.3, random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 200) (60000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work with X_train, X_test, y_train, y_test\n",
    "# Create an object of Logistic Regression with parameters C and class_weight\n",
    "logist = LogisticRegression(C = 0.001, class_weight = 'balanced')\n",
    "\n",
    "# Fit the training data on this object\n",
    "logist.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Target for validation dataset \n",
    "logist_pred = logist.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(Y_test, logist_pred):\n",
    "    logist_pred_var = [0 if i < 0.5 else 1 for i in logist_pred]\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(Y_test, logist_pred_var)) \n",
    "      \n",
    "    #print(classification_report(Y_test, logist_pred)) \n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, logist_pred, pos_label = 1)\n",
    "    print('AUC:')\n",
    "    print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[42214 11737]\n",
      " [ 1404  4645]]\n",
      "AUC:\n",
      "0.8541974369026266\n"
     ]
    }
   ],
   "source": [
    "performance(y_test, logist_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=0.7, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=80, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=2019,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Decision Tree Classifier object with few parameters\n",
    "tree_clf = DecisionTreeClassifier(class_weight = 'balanced', random_state = 2019, \n",
    "                                  max_features = 0.7, min_samples_leaf = 80)\n",
    "\n",
    "# Fit the object on training data\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[35314 18637]\n",
      " [ 2629  3420]]\n",
      "AUC:\n",
      "0.6514727493199708\n"
     ]
    }
   ],
   "source": [
    "# Predict for validation set and check the performance\n",
    "tree_preds = tree_clf.predict_proba(X_test)[:, 1]\n",
    "performance(y_test, tree_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features=0.5,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=25,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=25, n_jobs=1, oob_score=False, random_state=2019,\n",
       "            verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Forest Object using the mentioned parameters\n",
    "random_forest = RandomForestClassifier(n_estimators = 25, random_state = 2019, verbose = 1, #n_estimators = 100\n",
    "                                      class_weight = 'balanced', max_features = 0.5, \n",
    "                                       min_samples_leaf = 25) # min_samples_leaf = 100\n",
    "\n",
    "# Fit the object on training set \n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[51972  1979]\n",
      " [ 4749  1300]]\n",
      "AUC:\n",
      "0.7754952626738174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Predict the validation set target and check the performance\n",
    "forest_preds = random_forest.predict_proba(X_test)[:, 1]\n",
    "performance(y_test, forest_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Dropout, RepeatVector, Lambda, Permute, Activation, Masking, Reshape\n",
    "from keras.layers import recurrent, Input, TimeDistributed, add, concatenate, Multiply, Bidirectional\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.metrics import categorical_accuracy\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "#from keras.utils.visualize_util import plot\n",
    "from keras.layers.core import Layer\n",
    "\n",
    "from keras.activations import softmax, tanh, sigmoid, hard_sigmoid, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(in_shape):\n",
    "    adam = Adam(lr = 0.0003)  # Best learning found in previous exp\n",
    "    input_layer = Input(shape = (in_shape,), name = 'input_layer')\n",
    "    dense = Dense(100, activation = 'relu')(input_layer)\n",
    "    #dense = Dropout(0.35)(dense)\n",
    "    dense = Dense(50, activation = 'relu')(dense)\n",
    "    dense = Dropout(0.30)(dense)\n",
    "    output = Dense(2, activation = 'softmax')(dense)\n",
    "    model = Model(inputs = input_layer, outputs = output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    #model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    #tf_thetas = tf.get_variable(\"tf_thetas\",\n",
    "    #                        initializer=thetas)\n",
    "\n",
    "    #sample_output = Lambda(lambda x: \n",
    "    #               gumbel_softmax(x, temperature,  hard = hard_val), \n",
    "    #               output_shape = (2,))(output)\n",
    "    #cond_prob = Lambda(lambda x: tf.einsum('ai,ij->aj', x[0], tf_thetas*1.),\n",
    "    #          output_shape = (2, ))([sample_output])\n",
    "\n",
    "    #model_ask = Model(inputs = input_layer, outputs = cond_prob)\n",
    "    #model_ask.compile(loss = 'categorical_crossentropy', \n",
    "    #              optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model#, model_ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.choice(len(X_train), len(X_train), replace = False)\n",
    "\n",
    "X_train_nn = X_train.iloc[random_idx]\n",
    "y_train_nn = y_train.iloc[random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = create_models(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary_train = to_categorical(y_train)\n",
    "y_binary_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "140000/140000 [==============================] - 13s 94us/step - loss: 0.3224 - acc: 0.9012 - val_loss: 0.2596 - val_acc: 0.9029\n",
      "Epoch 2/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2621 - acc: 0.9061 - val_loss: 0.2552 - val_acc: 0.9040\n",
      "Epoch 3/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2567 - acc: 0.9077 - val_loss: 0.2485 - val_acc: 0.9094\n",
      "Epoch 4/50\n",
      "140000/140000 [==============================] - 14s 97us/step - loss: 0.2538 - acc: 0.9079 - val_loss: 0.2484 - val_acc: 0.9100\n",
      "Epoch 5/50\n",
      "140000/140000 [==============================] - 14s 101us/step - loss: 0.2527 - acc: 0.9085 - val_loss: 0.2458 - val_acc: 0.9104\n",
      "Epoch 6/50\n",
      "140000/140000 [==============================] - 13s 94us/step - loss: 0.2502 - acc: 0.9089 - val_loss: 0.2456 - val_acc: 0.9099\n",
      "Epoch 7/50\n",
      "140000/140000 [==============================] - 13s 94us/step - loss: 0.2500 - acc: 0.9088 - val_loss: 0.2437 - val_acc: 0.9105\n",
      "Epoch 8/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2484 - acc: 0.9093 - val_loss: 0.2488 - val_acc: 0.9104\n",
      "Epoch 9/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2478 - acc: 0.9093 - val_loss: 0.2705 - val_acc: 0.9054\n",
      "Epoch 10/50\n",
      "140000/140000 [==============================] - 13s 94us/step - loss: 0.2480 - acc: 0.9092 - val_loss: 0.2488 - val_acc: 0.9098\n",
      "Epoch 11/50\n",
      "140000/140000 [==============================] - 13s 92us/step - loss: 0.2465 - acc: 0.9097 - val_loss: 0.2440 - val_acc: 0.9106\n",
      "Epoch 12/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2470 - acc: 0.9097 - val_loss: 0.2437 - val_acc: 0.9105\n",
      "Epoch 13/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2467 - acc: 0.9096 - val_loss: 0.2452 - val_acc: 0.9112\n",
      "Epoch 14/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2461 - acc: 0.9098 - val_loss: 0.2658 - val_acc: 0.8995\n",
      "Epoch 15/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2455 - acc: 0.9100 - val_loss: 0.2505 - val_acc: 0.9085\n",
      "Epoch 16/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2454 - acc: 0.9098 - val_loss: 0.2444 - val_acc: 0.9098\n",
      "Epoch 17/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2450 - acc: 0.9103 - val_loss: 0.2434 - val_acc: 0.9103\n",
      "Epoch 18/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2451 - acc: 0.9102 - val_loss: 0.2440 - val_acc: 0.9106\n",
      "Epoch 19/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2456 - acc: 0.9097 - val_loss: 0.2464 - val_acc: 0.9102\n",
      "Epoch 20/50\n",
      "140000/140000 [==============================] - 13s 92us/step - loss: 0.2444 - acc: 0.9106 - val_loss: 0.2499 - val_acc: 0.9076\n",
      "Epoch 21/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2445 - acc: 0.9106 - val_loss: 0.2448 - val_acc: 0.9105\n",
      "Epoch 22/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2445 - acc: 0.9102 - val_loss: 0.2432 - val_acc: 0.9101\n",
      "Epoch 23/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2440 - acc: 0.9107 - val_loss: 0.2466 - val_acc: 0.9095\n",
      "Epoch 24/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2438 - acc: 0.9108 - val_loss: 0.2461 - val_acc: 0.9102\n",
      "Epoch 25/50\n",
      "140000/140000 [==============================] - 13s 92us/step - loss: 0.2438 - acc: 0.9105 - val_loss: 0.2485 - val_acc: 0.9092\n",
      "Epoch 26/50\n",
      "140000/140000 [==============================] - 14s 99us/step - loss: 0.2434 - acc: 0.9109 - val_loss: 0.2445 - val_acc: 0.9104\n",
      "Epoch 27/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2433 - acc: 0.9109 - val_loss: 0.2442 - val_acc: 0.9101\n",
      "Epoch 28/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2428 - acc: 0.9108 - val_loss: 0.2556 - val_acc: 0.9098\n",
      "Epoch 29/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2430 - acc: 0.9106 - val_loss: 0.2428 - val_acc: 0.9112\n",
      "Epoch 30/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2425 - acc: 0.9108 - val_loss: 0.2443 - val_acc: 0.9094\n",
      "Epoch 31/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2425 - acc: 0.9111 - val_loss: 0.2453 - val_acc: 0.9090\n",
      "Epoch 32/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2425 - acc: 0.9111 - val_loss: 0.2410 - val_acc: 0.9112\n",
      "Epoch 33/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2419 - acc: 0.9106 - val_loss: 0.2442 - val_acc: 0.9092\n",
      "Epoch 34/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2424 - acc: 0.9113 - val_loss: 0.2428 - val_acc: 0.9106\n",
      "Epoch 35/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2424 - acc: 0.9109 - val_loss: 0.2416 - val_acc: 0.9108\n",
      "Epoch 36/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2418 - acc: 0.9107 - val_loss: 0.2457 - val_acc: 0.9097\n",
      "Epoch 37/50\n",
      "140000/140000 [==============================] - 12s 89us/step - loss: 0.2419 - acc: 0.9108 - val_loss: 0.2408 - val_acc: 0.9111\n",
      "Epoch 38/50\n",
      "140000/140000 [==============================] - 13s 89us/step - loss: 0.2414 - acc: 0.9109 - val_loss: 0.2531 - val_acc: 0.9056\n",
      "Epoch 39/50\n",
      "140000/140000 [==============================] - 13s 91us/step - loss: 0.2418 - acc: 0.9106 - val_loss: 0.2419 - val_acc: 0.9112\n",
      "Epoch 40/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2414 - acc: 0.9111 - val_loss: 0.2424 - val_acc: 0.9107\n",
      "Epoch 41/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2415 - acc: 0.9111 - val_loss: 0.2421 - val_acc: 0.9099\n",
      "Epoch 42/50\n",
      "140000/140000 [==============================] - 13s 91us/step - loss: 0.2412 - acc: 0.9109 - val_loss: 0.2421 - val_acc: 0.9101\n",
      "Epoch 43/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2407 - acc: 0.9115 - val_loss: 0.2466 - val_acc: 0.9083\n",
      "Epoch 44/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2405 - acc: 0.9117 - val_loss: 0.2456 - val_acc: 0.9113\n",
      "Epoch 45/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2411 - acc: 0.9116 - val_loss: 0.2419 - val_acc: 0.9110\n",
      "Epoch 46/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2413 - acc: 0.9109 - val_loss: 0.2438 - val_acc: 0.9106\n",
      "Epoch 47/50\n",
      "140000/140000 [==============================] - 13s 91us/step - loss: 0.2407 - acc: 0.9109 - val_loss: 0.2416 - val_acc: 0.9121\n",
      "Epoch 48/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2407 - acc: 0.9113 - val_loss: 0.2414 - val_acc: 0.9113\n",
      "Epoch 49/50\n",
      "140000/140000 [==============================] - 13s 91us/step - loss: 0.2405 - acc: 0.9113 - val_loss: 0.2427 - val_acc: 0.9111\n",
      "Epoch 50/50\n",
      "140000/140000 [==============================] - 13s 90us/step - loss: 0.2404 - acc: 0.9114 - val_loss: 0.2413 - val_acc: 0.9113\n"
     ]
    }
   ],
   "source": [
    "# Make severl models, computes and average them. Consider Kfold, SVM, NN, Logisteic Regression, Light GBM and several configurations of them\n",
    "h = model.fit(X_train, y_binary_train, \n",
    "              epochs = 50, validation_data = (X_test, y_binary_test),\n",
    "              batch_size = 25,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_nn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nn_predic = []\n",
    "for i in range(len(y_predicted_nn)):\n",
    "    if y_predicted_nn[i,0] > y_predicted_nn[i,1]:\n",
    "        temp_nn_predic.append(0)\n",
    "    else:\n",
    "        temp_nn_predic.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There is no gain with more layers!\n",
    "fpr_nn, tpr_nn, threshold_nn = roc_curve(y_test, temp_nn_predic)\n",
    "roc_auc_nn = auc(fpr_nn, tpr_nn)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_nn, tpr_nn, 'b', label = 'AUC = %0.2f' % roc_auc_nn)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: run several configurations for each model, then combine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
